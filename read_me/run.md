# PROSSIME RUN BISENET

| Run | Optimizer & lr | Scheduler | Loss  | Tecniche Extra   | Note  | DONE |
| --- | ---------------------------------- | ----------------------------------------------------- | ---- | ------------------------------------------------ | --------------------------------------------------- | ---------------------------|
| 1   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE\_main + 1.0×(CE\_aux1 + CE\_aux2)                                                                | –                                                | “Baseline” run con lr 0.00625 ➜ punto di partenza già ottimo e confermato.                          | * |
| 2   | SGD (lr=0.005, mom=0.9, wd=1e-4)   | Warmup 1100 iters 1e-6→0.005 + poly (power 0.9)       | CE\_main + 1.0×(CE\_aux1 + CE\_aux2)                                                                | –                                                | Stesso setting, ma lr più conservativo ➜ confronto diretto con baseline per stabilità e smoothness. | * |
| 3   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE\_main + 0.4×(CE\_aux1 + CE\_aux2)                                                                | –                                                | Minor weight su auxiliary (α=0.4) ➜ test del loro reale contributo.                                 |
| 4   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | – Ep 1–35: CE\_main + 1×(CE\_aux1 + CE\_aux2)<br>– Ep 36–50: Lovász\_main + 1×(CE\_aux1 + CE\_aux2) | –                                                | Fine-tuning Lovász negli ultimi 15 epoche ➜ test di potenziale boost mIoU finale.                   |
| 5   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE + Focal (γ=2)                                                                                    | –                                                | Combina Focal per gestire class imbalance ➜ test con cityscapes, utile per classi rare.             |
| 6   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE + Tversky (α=0.7, β=0.3)                                                                         | –                                                | Test di loss Tversky (già promettente nei tuoi run!) ➜ vedi stabilità e mIoU migliorato.            |
| 7   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | – Ep 1–35: CE + Tversky<br>– Ep 36–50: Lovász\_main + 1×(CE\_aux1 + CE\_aux2)                       | –                                                | Strategia loss dinamica ➜ Tversky stabilizza, Lovász spinge la mIoU finale.                         |
| 8   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE\_main + 1.0×(CE\_aux1 + CE\_aux2)                                                                | **Gradient Accumulation ×2** (batch effettivo=8) | Stesso lr, ma stabilità e BatchNorm migliorati ➜ +1–2% mIoU attesi.                                 |
| 9   | SGD (lr=0.00625, mom=0.9, wd=1e-4) | **Warmup 2500 iters** 1e-6→0.00625 + poly (power 0.9) | CE\_main + 1.0×(CE\_aux1 + CE\_aux2)                                                                | –                                                | Warmup più lungo ➜ ottimale per evitare spike in primissime epoche (potenziale +0.5–1% mIoU).       |
| 10  | SGD (lr=0.00625, mom=0.9, wd=1e-4) | Warmup 1100 iters 1e-6→0.00625 + poly (power 0.9)     | CE con class weights:<br>`total_loss = wCE_main + (wCE_aux1 + wCE_aux2)`                            | –                                                | Bilancia pesi per classi rare ➜ test bilanciamento mIoU.                                            |
